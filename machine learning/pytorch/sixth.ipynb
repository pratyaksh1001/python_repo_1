{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import plotly.express as px\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Heart Prediction Quantum Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features=len(df.columns)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8.362241\n",
       "1       9.249002\n",
       "2       7.942542\n",
       "3       6.495155\n",
       "4       7.653900\n",
       "         ...    \n",
       "495     9.303403\n",
       "496     9.067889\n",
       "497     8.718708\n",
       "498     7.337650\n",
       "499    10.492950\n",
       "Name: QuantumPatternFeature, Length: 500, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"QuantumPatternFeature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "495    0\n",
       "496    0\n",
       "497    1\n",
       "498    0\n",
       "499    0\n",
       "Name: Gender, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Linear(in_features,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64,16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16,1)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.layer1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>QuantumPatternFeature</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>191</td>\n",
       "      <td>107</td>\n",
       "      <td>8.362241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>249</td>\n",
       "      <td>89</td>\n",
       "      <td>9.249002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>190</td>\n",
       "      <td>82</td>\n",
       "      <td>7.942542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>183</td>\n",
       "      <td>101</td>\n",
       "      <td>6.495155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>166</td>\n",
       "      <td>103</td>\n",
       "      <td>7.653900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>292</td>\n",
       "      <td>116</td>\n",
       "      <td>9.303403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>248</td>\n",
       "      <td>114</td>\n",
       "      <td>9.067889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>175</td>\n",
       "      <td>75</td>\n",
       "      <td>8.718708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>157</td>\n",
       "      <td>101</td>\n",
       "      <td>7.337650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>249</td>\n",
       "      <td>89</td>\n",
       "      <td>10.492950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  BloodPressure  Cholesterol  HeartRate  \\\n",
       "0     68       1            105          191        107   \n",
       "1     58       0             97          249         89   \n",
       "2     44       0             93          190         82   \n",
       "3     72       1             93          183        101   \n",
       "4     37       0            145          166        103   \n",
       "..   ...     ...            ...          ...        ...   \n",
       "495   34       0            126          292        116   \n",
       "496   41       0            164          248        114   \n",
       "497   45       1            159          175         75   \n",
       "498   55       0            107          157        101   \n",
       "499   55       0            174          249         89   \n",
       "\n",
       "     QuantumPatternFeature  HeartDisease  \n",
       "0                 8.362241             1  \n",
       "1                 9.249002             0  \n",
       "2                 7.942542             1  \n",
       "3                 6.495155             1  \n",
       "4                 7.653900             1  \n",
       "..                     ...           ...  \n",
       "495               9.303403             0  \n",
       "496               9.067889             0  \n",
       "497               8.718708             0  \n",
       "498               7.337650             1  \n",
       "499              10.492950             0  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.Tensor(df.drop([\"HeartDisease\"],axis=1).to_numpy())\n",
    "y=torch.Tensor(df[\"HeartDisease\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 51.0000,   1.0000, 148.0000, 199.0000,  76.0000,   8.8898],\n",
       "        [ 51.0000,   1.0000, 153.0000, 155.0000,  70.0000,   8.3169],\n",
       "        [ 41.0000,   0.0000, 142.0000, 150.0000,  66.0000,   9.1512],\n",
       "        ...,\n",
       "        [ 33.0000,   1.0000,  92.0000, 186.0000,  69.0000,   9.0491],\n",
       "        [ 57.0000,   0.0000, 121.0000, 221.0000,  84.0000,   7.9975],\n",
       "        [ 32.0000,   0.0000, 140.0000, 182.0000,  84.0000,   7.7132]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 50.0000,   1.0000, 114.0000, 271.0000,  73.0000,   8.6316],\n",
       "        [ 62.0000,   0.0000, 136.0000, 151.0000,  80.0000,   6.8984],\n",
       "        [ 65.0000,   1.0000, 179.0000, 279.0000, 108.0000,   9.1807],\n",
       "        [ 71.0000,   1.0000, 103.0000, 222.0000,  93.0000,   7.1834],\n",
       "        [ 70.0000,   1.0000, 102.0000, 287.0000,  85.0000,   8.5965],\n",
       "        [ 57.0000,   0.0000,  97.0000, 188.0000, 103.0000,   7.9620],\n",
       "        [ 42.0000,   0.0000, 102.0000, 201.0000,  71.0000,   7.1339],\n",
       "        [ 40.0000,   0.0000, 118.0000, 161.0000,  74.0000,   7.7657],\n",
       "        [ 65.0000,   0.0000, 122.0000, 238.0000,  85.0000,   7.3811],\n",
       "        [ 32.0000,   0.0000, 170.0000, 254.0000,  93.0000,   8.5092],\n",
       "        [ 47.0000,   0.0000, 160.0000, 244.0000,  95.0000,   9.7341],\n",
       "        [ 45.0000,   1.0000, 170.0000, 257.0000, 103.0000,   9.6069],\n",
       "        [ 59.0000,   0.0000, 122.0000, 210.0000,  89.0000,   9.3736],\n",
       "        [ 38.0000,   0.0000, 136.0000, 258.0000,  75.0000,   9.0400],\n",
       "        [ 58.0000,   0.0000, 122.0000, 164.0000,  68.0000,   8.6081],\n",
       "        [ 33.0000,   0.0000, 143.0000, 171.0000,  63.0000,   7.6777],\n",
       "        [ 68.0000,   0.0000, 144.0000, 161.0000,  92.0000,   6.5108],\n",
       "        [ 31.0000,   1.0000, 106.0000, 230.0000,  74.0000,   8.1304],\n",
       "        [ 30.0000,   0.0000, 101.0000, 242.0000, 109.0000,   9.0049],\n",
       "        [ 31.0000,   0.0000, 119.0000, 195.0000, 106.0000,   8.1039],\n",
       "        [ 35.0000,   1.0000, 171.0000, 174.0000,  62.0000,   7.4923],\n",
       "        [ 79.0000,   1.0000, 118.0000, 195.0000,  74.0000,   6.6257],\n",
       "        [ 32.0000,   1.0000, 124.0000, 210.0000,  84.0000,   8.1232],\n",
       "        [ 71.0000,   1.0000,  90.0000, 252.0000,  94.0000,   8.4503],\n",
       "        [ 53.0000,   1.0000, 151.0000, 160.0000,  95.0000,   8.6118],\n",
       "        [ 77.0000,   1.0000,  98.0000, 175.0000,  86.0000,   7.3597],\n",
       "        [ 65.0000,   1.0000, 175.0000, 229.0000, 115.0000,   7.9961],\n",
       "        [ 55.0000,   1.0000, 145.0000, 222.0000,  69.0000,   9.9221],\n",
       "        [ 48.0000,   1.0000,  99.0000, 194.0000,  65.0000,   7.9205],\n",
       "        [ 31.0000,   0.0000, 108.0000, 235.0000, 103.0000,   7.6034],\n",
       "        [ 73.0000,   0.0000, 103.0000, 238.0000,  63.0000,   8.1243],\n",
       "        [ 40.0000,   1.0000, 149.0000, 156.0000,  78.0000,   8.5392],\n",
       "        [ 32.0000,   1.0000, 138.0000, 259.0000,  78.0000,   9.6844],\n",
       "        [ 39.0000,   1.0000, 106.0000, 211.0000, 108.0000,   8.9373],\n",
       "        [ 75.0000,   0.0000, 138.0000, 166.0000,  74.0000,   6.6526],\n",
       "        [ 71.0000,   0.0000, 118.0000, 200.0000, 108.0000,   7.6202],\n",
       "        [ 49.0000,   0.0000, 102.0000, 199.0000,  63.0000,   7.8192],\n",
       "        [ 64.0000,   0.0000, 152.0000, 233.0000,  83.0000,   7.9858],\n",
       "        [ 74.0000,   1.0000,  96.0000, 194.0000,  68.0000,   8.2649],\n",
       "        [ 49.0000,   1.0000, 124.0000, 152.0000, 107.0000,   8.8897],\n",
       "        [ 33.0000,   0.0000, 112.0000, 168.0000,  79.0000,   8.1584],\n",
       "        [ 37.0000,   1.0000, 121.0000, 155.0000,  94.0000,   7.7600],\n",
       "        [ 34.0000,   1.0000, 119.0000, 169.0000,  97.0000,   8.2247],\n",
       "        [ 33.0000,   0.0000,  90.0000, 182.0000,  69.0000,   8.3830],\n",
       "        [ 71.0000,   0.0000, 104.0000, 198.0000, 102.0000,   7.0428],\n",
       "        [ 54.0000,   1.0000, 149.0000, 154.0000,  87.0000,   8.2746],\n",
       "        [ 62.0000,   1.0000, 125.0000, 233.0000,  72.0000,   7.6376],\n",
       "        [ 44.0000,   0.0000, 121.0000, 276.0000, 101.0000,   8.9703],\n",
       "        [ 30.0000,   1.0000, 153.0000, 228.0000,  96.0000,   8.0574],\n",
       "        [ 36.0000,   0.0000, 127.0000, 172.0000,  88.0000,   8.1622],\n",
       "        [ 53.0000,   1.0000, 150.0000, 176.0000,  97.0000,   8.9848],\n",
       "        [ 61.0000,   0.0000,  95.0000, 166.0000, 112.0000,   6.9717],\n",
       "        [ 50.0000,   1.0000, 150.0000, 260.0000,  82.0000,   8.9616],\n",
       "        [ 71.0000,   0.0000, 134.0000, 247.0000,  65.0000,   7.7230],\n",
       "        [ 58.0000,   0.0000,  97.0000, 249.0000,  89.0000,   9.2490],\n",
       "        [ 48.0000,   1.0000, 140.0000, 280.0000, 114.0000,   9.9355],\n",
       "        [ 55.0000,   1.0000, 158.0000, 245.0000,  86.0000,   8.9500],\n",
       "        [ 64.0000,   0.0000, 164.0000, 188.0000, 109.0000,   8.3512],\n",
       "        [ 69.0000,   1.0000, 157.0000, 161.0000, 118.0000,   7.8521],\n",
       "        [ 38.0000,   0.0000, 125.0000, 208.0000,  69.0000,   9.3401],\n",
       "        [ 50.0000,   1.0000, 127.0000, 209.0000,  60.0000,   7.8911],\n",
       "        [ 42.0000,   1.0000, 123.0000, 169.0000,  92.0000,   7.8081],\n",
       "        [ 79.0000,   0.0000, 121.0000, 237.0000,  69.0000,   8.2939],\n",
       "        [ 51.0000,   0.0000, 138.0000, 225.0000, 109.0000,   9.7892],\n",
       "        [ 47.0000,   1.0000, 141.0000, 249.0000,  93.0000,   9.1284],\n",
       "        [ 61.0000,   0.0000, 174.0000, 250.0000,  63.0000,   8.3666],\n",
       "        [ 65.0000,   0.0000,  91.0000, 226.0000, 108.0000,   8.0758],\n",
       "        [ 41.0000,   0.0000, 164.0000, 248.0000, 114.0000,   9.0679],\n",
       "        [ 66.0000,   0.0000, 109.0000, 205.0000,  91.0000,   6.5392],\n",
       "        [ 67.0000,   1.0000, 159.0000, 195.0000,  79.0000,   8.5918],\n",
       "        [ 35.0000,   0.0000, 127.0000, 193.0000, 116.0000,   8.1305],\n",
       "        [ 30.0000,   0.0000, 159.0000, 252.0000,  60.0000,   7.7530],\n",
       "        [ 73.0000,   1.0000, 174.0000, 161.0000,  99.0000,   7.9447],\n",
       "        [ 63.0000,   1.0000, 164.0000, 221.0000, 113.0000,   8.5134],\n",
       "        [ 59.0000,   0.0000, 149.0000, 193.0000, 119.0000,   9.3602],\n",
       "        [ 41.0000,   1.0000, 170.0000, 266.0000,  82.0000,   8.6789],\n",
       "        [ 52.0000,   0.0000, 116.0000, 266.0000, 114.0000,   9.1469],\n",
       "        [ 58.0000,   0.0000,  93.0000, 252.0000,  74.0000,   8.6865],\n",
       "        [ 72.0000,   1.0000,  93.0000, 183.0000, 101.0000,   6.4952],\n",
       "        [ 40.0000,   1.0000, 158.0000, 155.0000, 100.0000,   7.8585],\n",
       "        [ 49.0000,   0.0000, 176.0000, 283.0000,  84.0000,   9.9704],\n",
       "        [ 31.0000,   0.0000, 152.0000, 242.0000,  63.0000,   8.2529],\n",
       "        [ 61.0000,   0.0000, 166.0000, 289.0000, 102.0000,   9.3705],\n",
       "        [ 54.0000,   0.0000,  97.0000, 185.0000,  62.0000,   7.5809],\n",
       "        [ 32.0000,   0.0000, 155.0000, 282.0000,  61.0000,   8.3030],\n",
       "        [ 76.0000,   1.0000, 136.0000, 262.0000,  99.0000,   8.8343],\n",
       "        [ 53.0000,   0.0000, 159.0000, 264.0000,  92.0000,   9.8503],\n",
       "        [ 52.0000,   0.0000, 152.0000, 213.0000, 109.0000,   9.9746],\n",
       "        [ 63.0000,   0.0000, 176.0000, 211.0000, 100.0000,   7.8281],\n",
       "        [ 35.0000,   0.0000, 167.0000, 171.0000,  97.0000,   8.7754],\n",
       "        [ 74.0000,   1.0000, 123.0000, 272.0000, 116.0000,   8.3483],\n",
       "        [ 41.0000,   0.0000, 179.0000, 256.0000,  76.0000,   9.3420],\n",
       "        [ 40.0000,   0.0000, 159.0000, 295.0000, 101.0000,   8.7667],\n",
       "        [ 61.0000,   1.0000, 163.0000, 271.0000,  67.0000,   9.8888],\n",
       "        [ 30.0000,   0.0000, 104.0000, 209.0000, 117.0000,   7.6330],\n",
       "        [ 51.0000,   1.0000,  98.0000, 207.0000, 115.0000,   8.1751],\n",
       "        [ 61.0000,   0.0000, 142.0000, 194.0000, 119.0000,   9.4156],\n",
       "        [ 69.0000,   1.0000, 136.0000, 188.0000,  71.0000,   7.3283],\n",
       "        [ 57.0000,   0.0000, 136.0000, 186.0000, 103.0000,   8.0662],\n",
       "        [ 76.0000,   1.0000, 122.0000, 204.0000, 118.0000,   7.2413]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Classifier(in_features=in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func=nn.BCELoss()\n",
    "optimizer=torch.optim.Adam(lr=0.01,params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "y_train=torch.unsqueeze(y_train,dim=1)\n",
    "y_test=torch.unsqueeze(y_test,dim=1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3588],\n",
      "        [ 0.1284],\n",
      "        [-0.2571],\n",
      "        [-0.0297],\n",
      "        [ 0.3614],\n",
      "        [-0.0122],\n",
      "        [ 0.3450],\n",
      "        [ 0.3817],\n",
      "        [-0.0261],\n",
      "        [ 0.0106],\n",
      "        [ 0.1989],\n",
      "        [-0.0504],\n",
      "        [-0.0732],\n",
      "        [-0.0939],\n",
      "        [-0.0141],\n",
      "        [ 0.1230],\n",
      "        [-0.1841],\n",
      "        [-0.1017],\n",
      "        [-0.0359],\n",
      "        [ 0.1773],\n",
      "        [ 0.2005],\n",
      "        [ 0.1083],\n",
      "        [-0.1191],\n",
      "        [ 0.0684],\n",
      "        [ 0.0467],\n",
      "        [ 0.1102],\n",
      "        [ 0.3925],\n",
      "        [ 0.3848],\n",
      "        [ 0.0114],\n",
      "        [-0.1134],\n",
      "        [-0.0163],\n",
      "        [ 0.0649],\n",
      "        [ 0.1614],\n",
      "        [ 0.4440],\n",
      "        [ 0.4462],\n",
      "        [ 0.4894],\n",
      "        [ 0.1573],\n",
      "        [-0.1146],\n",
      "        [-0.0787],\n",
      "        [ 0.1928],\n",
      "        [-0.0921],\n",
      "        [ 0.1705],\n",
      "        [ 0.1272],\n",
      "        [ 0.1829],\n",
      "        [ 0.0677],\n",
      "        [ 0.1936],\n",
      "        [ 0.3154],\n",
      "        [-0.0016],\n",
      "        [-0.0687],\n",
      "        [-0.1104],\n",
      "        [ 0.1777],\n",
      "        [ 0.0260],\n",
      "        [-0.0457],\n",
      "        [ 0.2331],\n",
      "        [ 0.1755],\n",
      "        [ 0.4573],\n",
      "        [ 0.1102],\n",
      "        [ 0.1551],\n",
      "        [ 0.2125],\n",
      "        [-0.0087],\n",
      "        [ 0.1214],\n",
      "        [-0.0954],\n",
      "        [-0.0905],\n",
      "        [ 0.4099],\n",
      "        [ 0.3291],\n",
      "        [-0.1088],\n",
      "        [ 0.2011],\n",
      "        [ 0.1422],\n",
      "        [-0.0177],\n",
      "        [-0.1124],\n",
      "        [ 0.0073],\n",
      "        [ 0.0083],\n",
      "        [ 0.4359],\n",
      "        [ 0.2285],\n",
      "        [-0.1529],\n",
      "        [-0.1192],\n",
      "        [ 0.0045],\n",
      "        [ 0.3751],\n",
      "        [ 0.4175],\n",
      "        [-0.1142],\n",
      "        [ 0.0618],\n",
      "        [-0.0836],\n",
      "        [ 0.1350],\n",
      "        [ 0.3974],\n",
      "        [-0.0070],\n",
      "        [-0.0669],\n",
      "        [ 0.0643],\n",
      "        [ 0.0701],\n",
      "        [ 0.2784],\n",
      "        [ 0.3742],\n",
      "        [ 0.1113],\n",
      "        [ 0.4426],\n",
      "        [ 0.4122],\n",
      "        [ 0.2980],\n",
      "        [ 0.4618],\n",
      "        [ 0.0828],\n",
      "        [ 0.1968],\n",
      "        [-0.0170],\n",
      "        [ 0.1511],\n",
      "        [-0.0176],\n",
      "        [ 0.2531],\n",
      "        [ 0.3965],\n",
      "        [-0.0826],\n",
      "        [ 0.2997],\n",
      "        [-0.1148],\n",
      "        [-0.1610],\n",
      "        [-0.1425],\n",
      "        [ 0.3625],\n",
      "        [-0.0880],\n",
      "        [-0.0844],\n",
      "        [ 0.1926],\n",
      "        [-0.1049],\n",
      "        [-0.1147],\n",
      "        [ 0.0931],\n",
      "        [ 0.2411],\n",
      "        [ 0.1234],\n",
      "        [ 0.0931],\n",
      "        [ 0.1828],\n",
      "        [ 0.0886],\n",
      "        [ 0.2067],\n",
      "        [ 0.0752],\n",
      "        [ 0.1207],\n",
      "        [ 0.6203],\n",
      "        [ 0.0677],\n",
      "        [ 0.1178],\n",
      "        [-0.1514],\n",
      "        [ 0.4145],\n",
      "        [ 0.1054],\n",
      "        [ 0.1864],\n",
      "        [ 0.1779],\n",
      "        [ 0.2938],\n",
      "        [ 0.2137],\n",
      "        [ 0.2380],\n",
      "        [ 0.1539],\n",
      "        [ 0.3854],\n",
      "        [ 0.2349],\n",
      "        [ 0.2891],\n",
      "        [ 0.3390],\n",
      "        [ 0.1060],\n",
      "        [ 0.0799],\n",
      "        [-0.0763],\n",
      "        [-0.2226],\n",
      "        [ 0.0880],\n",
      "        [ 0.3926],\n",
      "        [ 0.1038],\n",
      "        [ 0.1249],\n",
      "        [ 0.2937],\n",
      "        [ 0.3308],\n",
      "        [ 0.1570],\n",
      "        [-0.0964],\n",
      "        [ 0.1298],\n",
      "        [ 0.2145],\n",
      "        [ 0.1290],\n",
      "        [ 0.2311],\n",
      "        [ 0.1839],\n",
      "        [ 0.2316],\n",
      "        [ 0.0399],\n",
      "        [ 0.1329],\n",
      "        [ 0.2035],\n",
      "        [-0.0942],\n",
      "        [ 0.3874],\n",
      "        [ 0.1103],\n",
      "        [ 0.0511],\n",
      "        [ 0.2474],\n",
      "        [ 0.1603],\n",
      "        [-0.1589],\n",
      "        [ 0.2830],\n",
      "        [ 0.1643],\n",
      "        [-0.0364],\n",
      "        [ 0.1650],\n",
      "        [ 0.2240],\n",
      "        [ 0.2005],\n",
      "        [ 0.5673],\n",
      "        [-0.0523],\n",
      "        [ 0.1082],\n",
      "        [ 0.1293],\n",
      "        [ 0.3145],\n",
      "        [ 0.4900],\n",
      "        [ 0.2682],\n",
      "        [ 0.1273],\n",
      "        [ 0.4339],\n",
      "        [ 0.3031],\n",
      "        [ 0.2165],\n",
      "        [ 0.1660],\n",
      "        [ 0.4200],\n",
      "        [-0.0757],\n",
      "        [ 0.3019],\n",
      "        [-0.1133],\n",
      "        [ 0.0621],\n",
      "        [-0.1178],\n",
      "        [ 0.2855],\n",
      "        [ 0.5075],\n",
      "        [-0.1106],\n",
      "        [ 0.1875],\n",
      "        [ 0.4660],\n",
      "        [-0.1144],\n",
      "        [ 0.2741],\n",
      "        [-0.0128],\n",
      "        [ 0.0209],\n",
      "        [-0.0274],\n",
      "        [ 0.1501],\n",
      "        [ 0.0083],\n",
      "        [ 0.2293],\n",
      "        [-0.1283],\n",
      "        [-0.0061],\n",
      "        [-0.0419],\n",
      "        [ 0.0233],\n",
      "        [ 0.1202],\n",
      "        [ 0.0256],\n",
      "        [-0.0271],\n",
      "        [ 0.0679],\n",
      "        [-0.1051],\n",
      "        [-0.0900],\n",
      "        [-0.0900],\n",
      "        [ 0.0916],\n",
      "        [-0.0622],\n",
      "        [ 0.2346],\n",
      "        [ 0.2880],\n",
      "        [ 0.2617],\n",
      "        [ 0.0354],\n",
      "        [-0.1172],\n",
      "        [ 0.1043],\n",
      "        [-0.1104],\n",
      "        [ 0.3839],\n",
      "        [ 0.0809],\n",
      "        [ 0.4424],\n",
      "        [ 0.1833],\n",
      "        [ 0.2024],\n",
      "        [-0.0516],\n",
      "        [ 0.0560],\n",
      "        [-0.1142],\n",
      "        [ 0.2086],\n",
      "        [ 0.2142],\n",
      "        [ 0.4375],\n",
      "        [-0.1274],\n",
      "        [ 0.4427],\n",
      "        [-0.0143],\n",
      "        [-0.0319],\n",
      "        [ 0.3568],\n",
      "        [ 0.2693],\n",
      "        [ 0.0952],\n",
      "        [ 0.1136],\n",
      "        [ 0.1644],\n",
      "        [ 0.0940],\n",
      "        [ 0.1220],\n",
      "        [ 0.5710],\n",
      "        [ 0.1368],\n",
      "        [-0.1603],\n",
      "        [ 0.3608],\n",
      "        [-0.2260],\n",
      "        [-0.1631],\n",
      "        [-0.0752],\n",
      "        [ 0.4336],\n",
      "        [ 0.3122],\n",
      "        [-0.0961],\n",
      "        [ 0.1331],\n",
      "        [ 0.2951],\n",
      "        [ 0.0395],\n",
      "        [ 0.0816],\n",
      "        [ 0.2538],\n",
      "        [ 0.1890],\n",
      "        [ 0.1970],\n",
      "        [-0.0248],\n",
      "        [ 0.3514],\n",
      "        [ 0.0076],\n",
      "        [-0.2306],\n",
      "        [ 0.2701],\n",
      "        [ 0.3498],\n",
      "        [ 0.0698],\n",
      "        [ 0.1293],\n",
      "        [ 0.0871],\n",
      "        [ 0.1987],\n",
      "        [ 0.0419],\n",
      "        [ 0.2433],\n",
      "        [ 0.3794],\n",
      "        [-0.0031],\n",
      "        [ 0.2481],\n",
      "        [-0.0697],\n",
      "        [ 0.2940],\n",
      "        [-0.0413],\n",
      "        [ 0.0382],\n",
      "        [ 0.3160],\n",
      "        [ 0.2679],\n",
      "        [-0.0768],\n",
      "        [-0.0043],\n",
      "        [ 0.3387],\n",
      "        [ 0.1114],\n",
      "        [ 0.3990],\n",
      "        [ 0.3981],\n",
      "        [ 0.0280],\n",
      "        [-0.0232],\n",
      "        [ 0.1405],\n",
      "        [ 0.1025],\n",
      "        [-0.0949],\n",
      "        [-0.0346],\n",
      "        [ 0.0494],\n",
      "        [-0.0670],\n",
      "        [-0.0923],\n",
      "        [ 0.0348],\n",
      "        [-0.1036],\n",
      "        [ 0.0738],\n",
      "        [ 0.1461],\n",
      "        [ 0.1443],\n",
      "        [ 0.0557],\n",
      "        [ 0.5616],\n",
      "        [ 0.0841],\n",
      "        [-0.0177],\n",
      "        [ 0.2781],\n",
      "        [-0.0263],\n",
      "        [-0.0938],\n",
      "        [ 0.2421],\n",
      "        [ 0.0441],\n",
      "        [ 0.4307],\n",
      "        [ 0.4439],\n",
      "        [-0.0526],\n",
      "        [ 0.4400],\n",
      "        [ 0.1800],\n",
      "        [ 0.1332],\n",
      "        [ 0.4216],\n",
      "        [-0.0600],\n",
      "        [ 0.1011],\n",
      "        [ 0.1720],\n",
      "        [ 0.2121],\n",
      "        [ 0.2526],\n",
      "        [-0.1038],\n",
      "        [ 0.3568],\n",
      "        [ 0.1985],\n",
      "        [-0.0818],\n",
      "        [ 0.0891],\n",
      "        [-0.0196],\n",
      "        [ 0.1617],\n",
      "        [ 0.2199],\n",
      "        [ 0.2150],\n",
      "        [-0.0366],\n",
      "        [ 0.3829],\n",
      "        [ 0.3309],\n",
      "        [ 0.0658],\n",
      "        [ 0.4000],\n",
      "        [ 0.1646],\n",
      "        [-0.0252],\n",
      "        [ 0.1586],\n",
      "        [ 0.3730],\n",
      "        [ 0.1174],\n",
      "        [-0.0077],\n",
      "        [ 0.4255],\n",
      "        [ 0.2267],\n",
      "        [ 0.2724],\n",
      "        [ 0.5238],\n",
      "        [-0.0531],\n",
      "        [ 0.3661],\n",
      "        [-0.0807],\n",
      "        [-0.0592],\n",
      "        [ 0.1609],\n",
      "        [ 0.1040],\n",
      "        [-0.0313],\n",
      "        [-0.1129],\n",
      "        [-0.0916],\n",
      "        [-0.0178],\n",
      "        [ 0.1911],\n",
      "        [ 0.4795],\n",
      "        [ 0.3985],\n",
      "        [ 0.1417],\n",
      "        [-0.1156],\n",
      "        [ 0.0644],\n",
      "        [ 0.1457],\n",
      "        [ 0.5459],\n",
      "        [ 0.4123],\n",
      "        [ 0.1413],\n",
      "        [-0.1112],\n",
      "        [-0.2768],\n",
      "        [ 0.0565],\n",
      "        [-0.0263],\n",
      "        [ 0.1309],\n",
      "        [-0.1875],\n",
      "        [ 0.0231],\n",
      "        [-0.0251],\n",
      "        [-0.0976],\n",
      "        [ 0.1015],\n",
      "        [ 0.0684],\n",
      "        [ 0.2824],\n",
      "        [ 0.4322],\n",
      "        [ 0.4503],\n",
      "        [ 0.2900],\n",
      "        [ 0.0710],\n",
      "        [ 0.2093],\n",
      "        [-0.0284],\n",
      "        [ 0.4105],\n",
      "        [ 0.3245],\n",
      "        [ 0.1623],\n",
      "        [ 0.0772],\n",
      "        [-0.0452],\n",
      "        [ 0.1072],\n",
      "        [ 0.0686],\n",
      "        [ 0.1925],\n",
      "        [ 0.0597],\n",
      "        [ 0.4939],\n",
      "        [ 0.1245],\n",
      "        [ 0.1788],\n",
      "        [ 0.1548],\n",
      "        [ 0.1505]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m y_preds\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(x_train)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_preds)\n\u001b[0;32m----> 6\u001b[0m loss\u001b[38;5;241m=\u001b[39mloss_func(y_preds,y_train)\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/django/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/django/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/django/lib/python3.12/site-packages/torch/nn/modules/loss.py:699\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction\n\u001b[1;32m    701\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/django/lib/python3.12/site-packages/torch/nn/functional.py:3569\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3566\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3567\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight, reduction_enum)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_preds=model.forward(x_train)\n",
    "    print(y_preds)\n",
    "    loss=loss_func(y_preds,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res=model.forward(x_test)\n",
    "y_res=list(y_res)\n",
    "y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "for i in range(len(y_res)):\n",
    "    if int(int(y_test[i])==round(float(y_res[i]))):\n",
    "        x+=1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
